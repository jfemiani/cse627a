Quiz title: 05.1 – Feed Forward Network Functions  
Quiz description: This quiz tests conceptual and practical understanding of feed-forward neural networks as introduced in PRML Chapter 5. Topics include the structure and function of multilayer perceptrons (MLPs), forward and backward propagation, activation functions, weight-space symmetries, and the universal approximation property. Additional questions address common training pitfalls, optimization behaviors, and historical misconceptions that have shaped the development of neural networks.  
shuffle answers: true  
show correct answers: false


Title: concept-check – remember – non-edge – Universal Approximation Property
Points: 1
1. Which statement correctly describes the universal approximation property of neural networks?
a) Neural networks can approximate any discrete function exactly.
... Incorrect. Universal approximation refers specifically to continuous functions, not discrete functions.
*b) Neural networks with at least one hidden layer can approximate any continuous function to arbitrary accuracy, given enough hidden units.
... Correct. This is precisely what the universal approximation theorem states.
c) Neural networks require at least three hidden layers to approximate any function.
... Incorrect. The theorem requires only one hidden layer.
d) Universal approximation means neural networks can approximate only linear functions perfectly.
... Incorrect. The universal approximation theorem explicitly addresses nonlinear continuous functions.

Title: medium – understand – non-edge – Weight-space Symmetry
Points: 1
1. Which scenario demonstrates the concept of weight-space symmetry in neural networks?
a) Scaling all weights entering a hidden unit by a positive constant and dividing all outgoing weights from the same hidden unit by the same constant leaves the network output unchanged.
... Incorrect. Nonlinear activation functions do not generally allow such simple linear rescaling without altering outputs.
*b) Swapping two hidden units (including all their incoming and outgoing connections) does not alter the input-output mapping of the network.
... Correct. Hidden units can be permuted without changing the network's function due to symmetry.
c) Changing the activation function of a hidden unit and adjusting its biases correspondingly leaves the network's input-output mapping unchanged.
... Incorrect. Changing the activation function fundamentally alters the nonlinear transformation, even with bias adjustments.
d) Increasing all bias terms by the same nonzero constant uniformly leaves the network output unchanged.
... Incorrect. Uniform bias shifts typically change the activations and thus alter the output.

Title: medium – understand – non-edge – Neural Networks vs. Linear Models
Points: 1
1. What primarily distinguishes neural networks from linear models, such as polynomial or logistic regression?
a) Neural networks can only handle linear relationships in data.
... Incorrect. Neural networks specifically address nonlinear relationships.
b) Neural networks always use fewer parameters than linear models.
... Incorrect. Neural networks typically have many parameters.
*c) Neural networks learn nonlinear transformations adaptively from data.
... Correct. Adaptively learned nonlinear transformations distinguish neural networks from traditional linear models.
d) Neural networks require less computational effort during training.
... Incorrect. Neural networks usually require more computation during training compared to simpler linear models.

Title: concept-check – remember – non-edge – Hidden Units Definition
Points: 1
1. In a neural network, what is the primary role of hidden units?
a) Generate final output predictions by applying the output activation function directly to raw input features.
... Incorrect. Hidden units do not directly produce final outputs from raw inputs; this is the role of output units.
*b) Perform intermediate nonlinear transformations to extract useful features from input data.
... Correct. Hidden units apply nonlinear transformations, capturing intermediate features.
c) Linearly combine the predictions from multiple neural networks to improve accuracy.
... Incorrect. Combining predictions is ensemble learning, not the function of hidden units.
d) Adjust weights and biases automatically during forward propagation.
... Incorrect. Weight and bias adjustments occur during training (via backpropagation), not during forward propagation or by hidden units themselves.


Title: concept-check – remember – non-edge – Backpropagation Purpose
Points: 1
1. What is the primary purpose of the backpropagation algorithm in neural networks?
a) To select the best activation functions for hidden units automatically during training.
... Incorrect. Backpropagation uses fixed activation functions chosen by the designer.
b) To generate predictions by propagating inputs through the network layers.
... Incorrect. This describes forward propagation, not backpropagation.
*c) To efficiently compute gradients of the loss function with respect to network parameters.
... Correct. Backpropagation calculates these gradients efficiently for optimization.
d) To prevent overfitting by automatically removing redundant hidden units.
... Incorrect. Backpropagation doesn't automatically remove units; network pruning is a separate step.


Title: concept-check – understand – non-edge – Activation Function Purpose
Points: 1
1. Why do neural networks typically use nonlinear activation functions in hidden units?
a) Nonlinear functions always reduce the number of parameters required by the network.
... Incorrect. Nonlinear activations don't inherently reduce parameter count; they add representational power.
b) Nonlinear functions ensure the neural network outputs remain linearly related to inputs.
... Incorrect. Nonlinear activation functions break linearity, enabling more complex transformations.
*c) Nonlinear functions enable neural networks to model complex, nonlinear relationships in data.
... Correct. Nonlinear activations provide the expressive power needed to capture complex patterns.
d) Nonlinear functions speed up the forward propagation computation during inference.
... Incorrect. Nonlinear functions do not inherently speed up inference; they typically increase computational complexity.


Title: medium – understand – non-edge – Feed-forward Structure and Gradient Computation
Points: 1
1. Why is the feed-forward (acyclic) structure useful for efficiently training neural networks with backpropagation?
a) It ensures all computations within the network are linear, simplifying gradient calculations.
... Incorrect. Feed-forward networks typically involve nonlinear functions, not linear.
b) It automatically prevents overfitting by limiting the complexity of network architectures.
... Incorrect. Feed-forward structure alone doesn't directly limit complexity or prevent overfitting.
*c) It allows straightforward calculation of gradients by defining a clear computational order for forward and backward passes.
... Correct. Feed-forward structure ensures a clearly defined order of computations, making gradient calculations straightforward.
d) It eliminates the need for activation functions in hidden layers, reducing complexity.
... Incorrect. Feed-forward structure does not eliminate the use of activation functions; they remain essential for modeling nonlinearities.


Title: hard – analyze – non-edge – Historical Misconception on Network Depth
Points: 1
1. Historically, what misconception arose from the universal approximation theorem regarding neural network depth?
a) It suggested that neural networks with nonlinear activations were fundamentally limited compared to linear models.
... Incorrect. The theorem emphasizes the power of nonlinear activations, not their limitations.
b) It implied that deeper networks would always overfit, discouraging researchers from building deeper architectures.
... Incorrect. Concerns about overfitting apply generally, not uniquely to deeper networks.
*c) It led researchers to underestimate the practical advantages of deeper networks, believing shallow networks were sufficient.
... Correct. The theorem suggested shallow networks could approximate any function, leading to neglect of deeper architectures.
d) It encouraged researchers to discard hidden layers entirely, advocating purely linear network structures.
... Incorrect. The theorem specifically highlights the necessity of nonlinear hidden layers, not their removal.


Title: medium – understand – non-edge – Forward Propagation and Differentiability
Points: 1
1. Why is differentiability of each step in forward propagation important for training neural networks?
a) Because differentiable functions require fewer parameters to approximate a target function.
... Incorrect. Differentiability affects optimization, not parameter count.
*b) Because it enables gradient-based optimization methods to compute parameter updates effectively.
... Correct. Differentiability is essential for computing gradients during training.
c) Because non-differentiable functions produce more accurate outputs for classification tasks.
... Incorrect. Non-differentiable functions can disrupt training, not improve accuracy.
d) Because forward propagation is only possible for differentiable activation functions.
... Incorrect. Forward propagation can compute outputs even for non-differentiable functions; the issue arises in training.


Title: medium – analyze – non-edge – Limitations of Universal Approximation
Points: 1
1. What is a practical limitation of the universal approximation theorem in real-world neural network applications?
a) It assumes the training data must span all possible inputs to guarantee good test performance.
... Incorrect. The theorem makes no claim about generalization; it concerns approximation capacity on a compact domain.
*b) It does not specify how many hidden units are required to reach a desired approximation accuracy.
... Correct. The theorem is existential—it guarantees the existence of a solution, not the architecture or efficiency.
c) It only applies to networks trained with gradient descent.
... Incorrect. The theorem is independent of the training algorithm; it's a representational result.
d) It requires that the input data be normally distributed to ensure convergence.
... Incorrect. The theorem makes no distributional assumptions about the input data.


Title: medium – analyze – non-edge – Generalization and Model Complexity
Points: 1
1. Why might increasing the number of hidden units in a neural network hurt its generalization performance, even if training error decreases?
a) More hidden units always lead to better generalization because the model has greater capacity.
... Incorrect. Greater capacity can lead to overfitting if not properly regularized.
*b) The network may overfit the training data, capturing noise rather than underlying patterns.
... Correct. Excessive capacity allows the model to memorize training data instead of generalizing.
c) Hidden units reduce the expressiveness of the network by restricting the learned function class.
... Incorrect. More hidden units increase expressiveness, not reduce it.
d) Increasing hidden units automatically removes regularization, making the model untrainable.
... Incorrect. Regularization must be explicitly applied; it’s not automatically disabled by increasing size.


Title: medium – analyze – non-edge – Hessian Eigenvalues and Curvature
Points: 1
1. In the local quadratic approximation of the error function, what does a small eigenvalue of the Hessian matrix indicate?
a) A direction in which the error surface is steep and changes rapidly.
... Incorrect. That would correspond to a large eigenvalue.
*b) A direction in which the error surface is flat and changes slowly.
... Correct. Small eigenvalues indicate low curvature along their eigenvector direction.
c) That the network has reached a global minimum.
... Incorrect. Small eigenvalues don’t distinguish global from local minima.
d) That the error function is convex in that direction.
... Incorrect. Convexity depends on all eigenvalues being positive — not just one being small.

Title: medium – understand – non-edge – Batch vs Stochastic Gradient Descent
Points: 1
1. What is one reason stochastic gradient descent (SGD) may perform better than full batch gradient descent in training neural networks?
a) SGD uses the exact gradient, making convergence more precise.
... Incorrect. SGD uses noisy estimates of the gradient, not exact values.
*b) SGD introduces noise that can help escape shallow local minima and saddle points.
... Correct. The stochasticity allows exploration of the error surface, potentially avoiding poor minima.
c) SGD computes gradients faster by ignoring the loss function altogether.
... Incorrect. SGD still computes gradients based on the loss function; it just uses fewer samples per update.
d) SGD guarantees convergence to the global minimum if the learning rate is small enough.
... Incorrect. SGD may still get stuck in local minima, especially in nonconvex problems.


Title: medium – apply – edge – Debugging with Small Data Subsets
Points: 1
1. Why is it recommended to train on a small subset of the data before launching a full training run?
a) It guarantees better generalization on the test set by preventing overfitting.
... Incorrect. A small dataset is more prone to overfitting, not less.
*b) It allows quick detection of bugs in the training loop, such as NaNs or poor convergence.
... Correct. Small subsets run faster and let you catch issues early in the training process.
c) It forces the optimizer to explore the loss landscape more thoroughly.
... Incorrect. Small datasets usually reduce variability and do not guarantee better exploration.
d) It helps ensure that the model performs well even with minimal training data.
... Incorrect. The goal is debugging, not optimizing for low-data performance.


Title: medium – apply – edge – Multi-Term Loss Function Design
Points: 1
1. In practical neural network training, why might the loss function be written as a sum of weighted components like $\mathcal{L} = \alpha_0 \mathcal{L}_0 + \alpha_1 \mathcal{L}_1 + \dots$?
a) To increase the number of optimization steps during training.
... Incorrect. The number of steps is unrelated to how many terms are in the loss.
*b) To capture multiple objectives or constraints that reflect desirable properties of the output.
... Correct. Real-world training often balances several loss terms, such as accuracy, smoothness, or domain-specific constraints.
c) To reduce the dimensionality of the parameter space.
... Incorrect. Adding more loss terms doesn't change the number of model parameters.
d) To enforce dropout and batch normalization implicitly.
... Incorrect. Regularization techniques like dropout are separate from multi-term loss formulations.


Title: medium – apply – edge – Softmax Numerical Stability Trick
Points: 1
1. Why is it common practice to subtract the maximum activation from all logits before applying the softmax function?
a) It increases the confidence of the predicted class by sharpening the output distribution.
... Incorrect. It doesn’t change the output probabilities’ relative values.
*b) It improves numerical stability by preventing large exponentials from overflowing.
... Correct. Subtracting the max ensures that all exponentials are ≤ 1, avoiding overflow.
c) It ensures that all outputs lie strictly between 0 and 1.
... Incorrect. Softmax already produces values in (0, 1), regardless of shifting.
d) It forces the average output probability to be 1/K across all classes.
... Incorrect. The mean of the output depends on the input values, not a uniform prior.


Title: medium – understand – non-edge – Minimizing Negative Log-Likelihood
Points: 1
1. Why is training a neural network typically formulated as minimizing the negative log-likelihood (error) rather than maximizing the likelihood directly?
a) Minimizing the loss allows gradient descent to converge to a unique global minimum.
... Incorrect. The loss surface is nonconvex, and gradient descent may converge to local minima regardless of sign convention.
*b) Minimization aligns with optimization conventions and allows interpreting the loss as an energy function.
... Correct. Negative log-likelihood minimization is mathematically equivalent to maximizing likelihood and aligns with common optimization paradigms.
c) Maximizing the likelihood directly would require computing the full partition function of the model.
... Incorrect. This concern applies to some probabilistic models (like CRFs), not neural networks with standard output layers.
d) Loss minimization guarantees that the model assigns high confidence to all predictions.
... Incorrect. Minimization doesn't guarantee high confidence — only alignment with the training targets.


Title: medium – apply – edge – Pitfall: CrossEntropyLoss and Softmax
Points: 1
1. In PyTorch, what is the correct way to compute the loss for multiclass classification using `CrossEntropyLoss`?
a) Apply softmax to the output layer and then pass the result to `CrossEntropyLoss`.
... Incorrect. This double-applies softmax and leads to incorrect gradients and numerical instability.
*b) Pass the raw output logits directly to `CrossEntropyLoss`, which applies softmax internally.
... Correct. PyTorch expects raw scores and handles softmax + log internally for numerical stability.
c) Use a sigmoid activation and then apply `BCELoss` for multiclass classification.
... Incorrect. Sigmoid + BCE is not suited for mutually exclusive classes.
d) Apply `log_softmax` manually and then use `CrossEntropyLoss`.
... Incorrect. `CrossEntropyLoss` already includes `log_softmax`, so applying it again is redundant and incorrect.
